# S3 Object Storage

SeaTable allows the use of S3 from AWS or any other S3 compatible object storage e.g. from Exoscale, Minio, OpenStack Swift and Ceph's RGW. In S3 SeaTable stores:

- Base snapshots
- Content of picture and file columns

!!! note "Bucket naming conventions"

    No matter if you using AWS or any other S3 compatible object storage, we recommend that you follow S3 naming rules. When you create buckets on S3, please read the [S3 rules for naming](https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html) first. Note, especially do not use capital letters in the name of the bucket (do not use camel-style naming, such as MyCommitObjects).

    === "Good naming of a bucket"

        - seatable-blocks
        - seatable-commits
        - customer-name-storage

    === "Bad naming of a bucket"

        - SeaTableBlocks
        - SUperIMPORTANTS3
        - seatable blocks

!!! warning "Restart required"

    Don't forget to restart SeaTable service after these configuration changes. Easiest is with
    ```
    docker exec -it ... seatable.sh restart
    ```

## Use S3 for base snapshots

The storage of base snapshots are configured in `dtable-storage-server.conf`. By default the section `[storage backend]` contains `type = local`. With this setting, all base snapshots are stored in the folder `/opt/seatable/seatable-data/seatable/storage-data`.

Switch the type to `type = s3` to use S3 Object storage. Depending on whether you are using AWS or an S3 compatible service, different configuration options must be used.

=== "AWS"

    AWS requires only a few settings. `key_id` and `key` are used to provide S3 authentication. You can find the `key_id` and `key` in the *Security Credentials* section of your AWS account page.

    ```
    [storage backend]
    type = s3
    bucket = ...
    key_id =
    key =
    ```

=== "Exoscale"

    Create the bucket and an IAM Key for accessing the S3 storage from exoscale.

    ```
    [storage backend]
    type = s3
    bucket = your-bucket-name
    host = sos-de-fra-1.exo.io
    use_https = true
    key_id = ...
    key = ...
    path_style_request = true
    use_v4_signature = false
    ```

=== "S3 compatible storage"

    Use the following settings to connect to your S3 compatible storage.

    ```
    [storage backend]
    type = s3
    bucket = ...
    host = ...
    use_https = true
    key_id =
    key =
    path_style_request = true
    use_v4_signature = false
    ```

    `host` is the address and port of the S3 compatible service. You can not add "http" or "https" before the option. By default, it will use http connection. If you want to use https connection, set the option:`hostuse_https = true`.

    `path_style_request` option tells Seatable to use the form `https://192.168.1.123:8080/bucketname/object` to access the object. In AWS S3 service, the default URL format is virtual host format, such as `https://bucketname.s3.amazonaws.com/object`. But general object storage products do not support this format.

## Use S3 for files and pictures

S3 Object storage for file and picture columns is configured in `/opt/seatable/seatable-data/seatable/conf/seafile.conf`. You have to add three new sections:

- [commit_object_backend]
- [fs_object_backend]
- [block_backend]

=== "AWS"

    ```
    [commit_object_backend]
    name = s3
    bucket = my-commit-objects
    key_id = your-key-id
    key = your-secret-key

    [fs_object_backend]
    name = s3
    bucket = my-fs-objects
    key_id = your-key-id
    key = your-secret-key

    [block_backend]
    name = s3
    bucket = my-block-objects
    key_id = your-key-id
    key = your-secret-key
    ```

=== "exoscale"

    ```
    [commit_object_backend]
    name = s3
    bucket = your-bucket-name
    host = sos-de-fra-1.exo.io
    key_id = ...
    key = ...
    use_https = true
    path_style_request = true

    [fs_object_backend]
    name = s3
    bucket = your-bucket-name
    host = sos-de-fra-1.exo.io
    key_id = ...
    key = ...
    use_https = true
    path_style_request = true

    [block_backend]
    name = s3
    bucket = your-bucket-name
    host = sos-de-fra-1.exo.io
    key_id = ...
    key = ...
    use_https = true
    path_style_request = true
    ```

=== "S3 compatible storage"

    ```
    [commit_object_backend]
    name = s3
    bucket = my-commit-objects
    key_id = your-key-id
    key = your-secret-key

    [fs_object_backend]
    name = s3
    bucket = my-fs-objects
    key_id = your-key-id
    key = your-secret-key

    [block_backend]
    name = s3
    bucket = my-block-objects
    key_id = your-key-id
    key = your-secret-key
    ```

## Advanced configurations

### Use the new AWS S3 service area

Since January 2014, the new AWS service area only provides version 4 certification and signing protocol support for S3. This includes such as China region, EU central regions.

To use S3 in the new service area, add the following additional options in the three buckets "commit_object_backend", "fs_object_backend", "block_backend":

```
use_v4_signature = true
aws_region = eu-central-1    # eu-central-1 for Frankfurt region
```

If you are using S3 in China or Germany, you also need to add the host configuration of the corresponding region under each bucket configuration section, for example, Beijing, China:

```
host = s3.cn-north-1.amazonaws.com.cn
```
